{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归 - 模型规范\n",
    "该笔记本演示了：\n",
    "\n",
    "0. 正确指定模型（基线）\n",
    "1. 型号不详\n",
    "     - 不相关的预测变量\n",
    "     - 相关预测变量\n",
    "2. 过度指定模型\n",
    "     - 完美的多重共线性\n",
    "     - 不同程度的多重共线性\n",
    "     - 包括不相关的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.正确指定模型（基线）\n",
    "\n",
    "- 我们按照正态分布随机生成 100 个不相关的 X1 和 X2。\n",
    "\n",
    "- 我们指定一条真正的回归线：$y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- 我们在回归模型中正确包含 X1 和 X2：y ~ X1 + X2（带截距）\n",
    "\n",
    "- 我们拟合 1000 个这样的回归模型，并检查估计值的偏差和精确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    X1 = np.random.randn(100) + 2\n",
    "    X2 = np.random.randn(100) + 2\n",
    "    \n",
    "    e = np.random.randn(100)\n",
    "    y = 3 + 2*X1 + 4*X2 + e\n",
    "    X = sm.add_constant(np.column_stack([X1,X2]))\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of estimates: [3.0037811  2.00347394 3.99617821]\n",
      "SE of estimates: [0.30086517 0.09971629 0.10145132]\n"
     ]
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "print(\"Average of estimates:\", np.mean(np.array(estimates),axis=0))\n",
    "print(\"SE of estimates:\", np.std(np.array(estimates),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 未指定型号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不相关的预测变量 (#1)\n",
    "- 我们按照正态分布随机生成 100 个不相关的 X1 和 X2。\n",
    "\n",
    "- 我们指定一条真正的回归线：$y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- 我们的回归模型中仅包含 X1：y ~ X1（带截距）\n",
    "\n",
    "- 我们拟合 1000 个这样的回归模型并检查偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    means = [2 , 2]\n",
    "    cov = [[1,0], [0,1]]\n",
    "    \n",
    "    X = np.random.multivariate_normal(means,cov,100)\n",
    "\n",
    "    e = np.random.randn(100)\n",
    "    \n",
    "    y = 3 + 2*X[:,0] + 4*X[:,1] + e\n",
    "    \n",
    "    X = sm.add_constant(X[:,0])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of estimates: [11.01614906  1.99128492]\n",
      "SE of estimates: [0.95786376 0.42621356]\n"
     ]
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "print(\"Average of estimates:\", np.mean(np.array(estimates),axis=0))\n",
    "\n",
    "print(\"SE of estimates:\", np.std(np.array(estimates),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到截距估计是**有偏**（只有当您省略的变量均值为零时才会无偏），并且 b1 的系数是**无偏**。 估计的 SE 远高于正确指定的模型中的 SE。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相关预测变量 (#2)\n",
    "- 我们按照双变量正态分布随机生成 100 个相关的 X1 和 X2（因此 X1 和 X2 的相关系数为 0.4）。\n",
    "\n",
    "- 我们指定一条真正的回归线：$y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- 我们的回归模型中仅包含 X1：y ~ X1（带截距）\n",
    "\n",
    "- 我们拟合 1000 个这样的回归模型并检查偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    means = [2, 2]\n",
    "    cov = [[1,0.4], [0.4,1]]\n",
    "    X = np.random.multivariate_normal(means,cov,100)\n",
    "\n",
    "    e = np.random.randn(100)\n",
    "    y = 3 + 2*X[:,0] + 4*X[:,1] + e\n",
    "    X = sm.add_constant(X[:,0])\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.77702431, 3.60628815])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "np.mean(np.array(estimates),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85773046, 0.38963273])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "np.std(np.array(estimates),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到截距估计是有**偏差的（只有当两个变量的均值都为零时，它才是无偏差的），并且 b1 的系数也相对于其真实值 2 有**偏差**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：当预测变量相关时，忽略一个变量会使其他估计产生偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 过度指定模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 完美多重共线性 (#1)\n",
    "- 我们按照正态分布随机生成 X1 的 100 个数据点。\n",
    "- 我们设置 X2 = 1 - X1\n",
    "\n",
    "- 我们指定一条真正的回归线：$y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- 我们只将回归模型拟合为：y ~ X1 + X2（带截距）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.randn(100)\n",
    "X2 = 1 - X1\n",
    "e = np.random.randn(100)\n",
    "\n",
    "y = 3 + 2*X1 + 4*X2 + e\n",
    "\n",
    "X = sm.add_constant(np.column_stack([X1,X2]))\n",
    "\n",
    "model = sm.OLS(y,X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   466.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 13 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>4.98e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:50:43</td>     <th>  Log-Likelihood:    </th> <td> -141.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   287.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   293.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.0724</td> <td>    0.075</td> <td>   54.100</td> <td> 0.000</td> <td>    3.923</td> <td>    4.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.0145</td> <td>    0.072</td> <td>   14.005</td> <td> 0.000</td> <td>    0.871</td> <td>    1.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.0579</td> <td>    0.045</td> <td>   67.296</td> <td> 0.000</td> <td>    2.968</td> <td>    3.148</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.402</td> <th>  Durbin-Watson:     </th> <td>   2.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.496</td> <th>  Jarque-Bera (JB):  </th> <td>   1.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.152</td> <th>  Prob(JB):          </th> <td>   0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.527</td> <th>  Cond. No.          </th> <td>1.32e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.91e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.826   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.825   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     466.2   \\\\\n",
       "\\textbf{Date:}             & Tue, 13 Feb 2024 & \\textbf{  Prob (F-statistic):} &  4.98e-39   \\\\\n",
       "\\textbf{Time:}             &     09:50:43     & \\textbf{  Log-Likelihood:    } &   -141.90   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     287.8   \\\\\n",
       "\\textbf{Df Residuals:}     &          98      & \\textbf{  BIC:               } &     293.0   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       4.0724  &        0.075     &    54.100  &         0.000        &        3.923    &        4.222     \\\\\n",
       "\\textbf{x1}    &       1.0145  &        0.072     &    14.005  &         0.000        &        0.871    &        1.158     \\\\\n",
       "\\textbf{x2}    &       3.0579  &        0.045     &    67.296  &         0.000        &        2.968    &        3.148     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.402 & \\textbf{  Durbin-Watson:     } &    2.156  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.496 & \\textbf{  Jarque-Bera (JB):  } &    1.313  \\\\\n",
       "\\textbf{Skew:}          &  0.152 & \\textbf{  Prob(JB):          } &    0.519  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.527 & \\textbf{  Cond. No.          } & 1.32e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.91e-30. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.826\n",
       "Model:                            OLS   Adj. R-squared:                  0.825\n",
       "Method:                 Least Squares   F-statistic:                     466.2\n",
       "Date:                Tue, 13 Feb 2024   Prob (F-statistic):           4.98e-39\n",
       "Time:                        09:50:43   Log-Likelihood:                -141.90\n",
       "No. Observations:                 100   AIC:                             287.8\n",
       "Df Residuals:                      98   BIC:                             293.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.0724      0.075     54.100      0.000       3.923       4.222\n",
       "x1             1.0145      0.072     14.005      0.000       0.871       1.158\n",
       "x2             3.0579      0.045     67.296      0.000       2.968       3.148\n",
       "==============================================================================\n",
       "Omnibus:                        1.402   Durbin-Watson:                   2.156\n",
       "Prob(Omnibus):                  0.496   Jarque-Bera (JB):                1.313\n",
       "Skew:                           0.152   Prob(JB):                        0.519\n",
       "Kurtosis:                       2.527   Cond. No.                     1.32e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.91e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多重共线性 (#2)\n",
    "- 我们按照双变量正态分布随机生成 100 个相关的 X1 和 X2，并让 X1 和 X2 具有不同程度的相关性（0、0.3、0.6、0.9、0.95 和 0.99）。\n",
    "\n",
    "- 我们指定一条真实的回归线：$y$ = 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- 我们在回归模型中包含 X1 和 X2：y ~ X1 + X2（为了简单起见，没有截距）\n",
    "\n",
    "- 对于每个预设的相关值，我们重复 1000 次以生成回归估计的采样分布。\n",
    "- 绘制采样分布图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to return the sampling distribution of regression coefficients \n",
    "# based on different degree of correlation between X1 and X2\n",
    "def simulation_multi_colinearity(cor):\n",
    "    params = []\n",
    "    for i in range(1000):\n",
    "        means = [2,2]\n",
    "        cov = [[1,cor], [cor,1]]\n",
    "        X = np.random.multivariate_normal(means,cov,100)\n",
    "        e = np.random.randn(100)*2\n",
    "        y = 2*X[:,0] + 4*X[:,1] + e\n",
    "        model = sm.OLS(y,X).fit()\n",
    "        params.append(model.params)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dist_0 = simulation_multi_colinearity(0)\n",
    "sampling_dist_0_3 = simulation_multi_colinearity(0.3)\n",
    "sampling_dist_0_6 = simulation_multi_colinearity(0.6)\n",
    "sampling_dist_0_9 = simulation_multi_colinearity(0.9)\n",
    "sampling_dist_0_95 = simulation_multi_colinearity(0.95)\n",
    "sampling_dist_0_99 = simulation_multi_colinearity(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE of estimates when X1 and X2 have a cor of 0: [0.14924138 0.15362695]\n",
      "SE of estimates when X1 and X2 have a cor of 0.3: [0.18184739 0.18149639]\n",
      "SE of estimates when X1 and X2 have a cor of 0.6: [0.23542159 0.23302496]\n",
      "SE of estimates when X1 and X2 have a cor of 0.9: [0.46005811 0.46522827]\n",
      "SE of estimates when X1 and X2 have a cor of 0.95: [0.62053723 0.61689469]\n",
      "SE of estimates when X1 and X2 have a cor of 0.99: [1.5058649  1.50165901]\n"
     ]
    }
   ],
   "source": [
    "print(\"SE of estimates when X1 and X2 have a cor of 0:\", np.std(sampling_dist_0,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.3:\", np.std(sampling_dist_0_3,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.6:\", np.std(sampling_dist_0_6,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.9:\", np.std(sampling_dist_0_9,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.95:\", np.std(sampling_dist_0_95,axis=0))\n",
    "print(\"SE of estimates when X1 and X2 have a cor of 0.99:\", np.std(sampling_dist_0_99,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of estimates when X1 and X2 have a cor of 0: [1.99528853 4.00220908]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.3: [1.99374527 4.00339456]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.6: [2.01461324 3.98911849]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.9: [2.02487827 3.97569048]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.95: [2.04199266 3.95822687]\n",
      "Mean of estimates when X1 and X2 have a cor of 0.99: [1.96516269 4.03487359]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of estimates when X1 and X2 have a cor of 0:\", np.mean(sampling_dist_0,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.3:\", np.mean(sampling_dist_0_3,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.6:\", np.mean(sampling_dist_0_6,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.9:\", np.mean(sampling_dist_0_9,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.95:\", np.mean(sampling_dist_0_95,axis=0))\n",
    "print(\"Mean of estimates when X1 and X2 have a cor of 0.99:\", np.mean(sampling_dist_0_99,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以观察到，模型中两个预测变量之间的相关程度不同，回归系数仍然**无偏**，但估计的标准误差根据相关程度**夸大**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 添加不相关的预测变量 (#2)\n",
    "- 我们按照正态分布随机生成 X1、X2 和 X3 的 100 个数据点。\n",
    "\n",
    "- 我们指定一条真正的回归线：$y$ = 3 + 2*$X_1$ + 4*$X_2$ + e\n",
    "\n",
    "- 我们在回归模型中包括 X1、X2 和 X3：y ~ X1（带截距）。 这里X3不应该在模型中，而是包含在内。\n",
    "\n",
    "- 我们拟合 1000 个这样的回归模型并检查偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = []\n",
    "for i in range(1000):\n",
    "    X1 = np.random.randn(100)\n",
    "    X2 = np.random.randn(100)\n",
    "    X3 = np.random.randn(100)\n",
    "    e = np.random.randn(100)\n",
    "\n",
    "    y = 3 + 2*X1 + 4*X2 + e\n",
    "\n",
    "    X = sm.add_constant(np.column_stack([X1,X2,X3]))\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    estimates.append(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of estimates: [ 3.00132214e+00  1.99576168e+00  3.99886082e+00 -2.36659646e-03]\n",
      "SE of estimates: [0.10146959 0.09980508 0.10321398 0.1018764 ]\n"
     ]
    }
   ],
   "source": [
    "#The averages of estimates across the 1000 replications are:\n",
    "print(\"Average of estimates:\", np.mean(np.array(estimates),axis=0))\n",
    "print(\"SE of estimates:\", np.std(np.array(estimates),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现 X1 和 X2 的估计是**无偏**，并且标准误差也很小。 X3 的估计值几乎为零，如果我们从 1000 个模型中检查一个模型，我们会发现该估计值在统计上并不显着。 从这个意义上讲，将不相关的随机数据纳入模型并没有多大害处。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   806.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 13 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>6.27e-68</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:50:44</td>     <th>  Log-Likelihood:    </th> <td> -138.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   285.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   295.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.0338</td> <td>    0.099</td> <td>   30.704</td> <td> 0.000</td> <td>    2.838</td> <td>    3.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.9591</td> <td>    0.094</td> <td>   20.781</td> <td> 0.000</td> <td>    1.772</td> <td>    2.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.9472</td> <td>    0.090</td> <td>   43.918</td> <td> 0.000</td> <td>    3.769</td> <td>    4.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1564</td> <td>    0.099</td> <td>    1.580</td> <td> 0.117</td> <td>   -0.040</td> <td>    0.353</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.692</td> <th>  Durbin-Watson:     </th> <td>   2.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.260</td> <th>  Jarque-Bera (JB):  </th> <td>   2.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.387</td> <th>  Prob(JB):          </th> <td>   0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.920</td> <th>  Cond. No.          </th> <td>    1.20</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.962   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.961   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     806.9   \\\\\n",
       "\\textbf{Date:}             & Tue, 13 Feb 2024 & \\textbf{  Prob (F-statistic):} &  6.27e-68   \\\\\n",
       "\\textbf{Time:}             &     09:50:44     & \\textbf{  Log-Likelihood:    } &   -138.60   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     285.2   \\\\\n",
       "\\textbf{Df Residuals:}     &          96      & \\textbf{  BIC:               } &     295.6   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       3.0338  &        0.099     &    30.704  &         0.000        &        2.838    &        3.230     \\\\\n",
       "\\textbf{x1}    &       1.9591  &        0.094     &    20.781  &         0.000        &        1.772    &        2.146     \\\\\n",
       "\\textbf{x2}    &       3.9472  &        0.090     &    43.918  &         0.000        &        3.769    &        4.126     \\\\\n",
       "\\textbf{x3}    &       0.1564  &        0.099     &     1.580  &         0.117        &       -0.040    &        0.353     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.692 & \\textbf{  Durbin-Watson:     } &    2.382  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.260 & \\textbf{  Jarque-Bera (JB):  } &    2.525  \\\\\n",
       "\\textbf{Skew:}          & -0.387 & \\textbf{  Prob(JB):          } &    0.283  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.920 & \\textbf{  Cond. No.          } &     1.20  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.962\n",
       "Model:                            OLS   Adj. R-squared:                  0.961\n",
       "Method:                 Least Squares   F-statistic:                     806.9\n",
       "Date:                Tue, 13 Feb 2024   Prob (F-statistic):           6.27e-68\n",
       "Time:                        09:50:44   Log-Likelihood:                -138.60\n",
       "No. Observations:                 100   AIC:                             285.2\n",
       "Df Residuals:                      96   BIC:                             295.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.0338      0.099     30.704      0.000       2.838       3.230\n",
       "x1             1.9591      0.094     20.781      0.000       1.772       2.146\n",
       "x2             3.9472      0.090     43.918      0.000       3.769       4.126\n",
       "x3             0.1564      0.099      1.580      0.117      -0.040       0.353\n",
       "==============================================================================\n",
       "Omnibus:                        2.692   Durbin-Watson:                   2.382\n",
       "Prob(Omnibus):                  0.260   Jarque-Bera (JB):                2.525\n",
       "Skew:                          -0.387   Prob(JB):                        0.283\n",
       "Kurtosis:                       2.920   Cond. No.                         1.20\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
